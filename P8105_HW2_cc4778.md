P8105_HW2_cc4778
================
Chee Kay Cheong

    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
    ## ✔ ggplot2 3.3.6     ✔ purrr   0.3.4
    ## ✔ tibble  3.1.8     ✔ dplyr   1.0.9
    ## ✔ tidyr   1.2.1     ✔ stringr 1.4.1
    ## ✔ readr   2.1.2     ✔ forcats 0.5.2
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()

# Problem 1

``` r
subway_data = read_csv("./Data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line:entry, vending, ada) %>%
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

I created a new dataset called `subway_data` that consists of 19
variables (columns) and 1868 observations (rows) which were extracted
from the original csv datafile
`NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. The original csv
dataset consists of 32 variables, but I only selected those that I want
to keep in my new dataset. So far, I have only cleaned the variable
names by making them all lowercase, and I changed the variable type for
`entry` from character to logical.

The 19 variables in this dataset are:

-   `line` (character)
-   `station_name` (character)
-   `station_latitude` (numeric)
-   `station_longitude` (numeric)
-   `route1` to `route7` (character) \<- 7 variables here
-   `route8` to `route11` (numeric) \<- 4 variables here
-   `entrance_type` (character)
-   `entry` (logical)
-   `vending` (character)
-   `ada` (logical)

As we can see from the variables and their types, this dataset is not
tidy enough. Not all “routes” are character vectors; some “routes” are
numeric. Also, it seems like all the routes should be combined into one
variable.

#### Questions

We will be using the data from `subway_data` to answer the following
questions:

1.  How many distinct stations are there?

``` r
subway_data %>% 
  select(station_name, line) %>% 
  distinct()
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # … with 455 more rows

Answer: There are **465** distinct stations.

2.  How many stations are ADA compliant?

``` r
subway_data %>%
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct()
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # … with 74 more rows

Answer: **84** stations are ADA compliant.

3.  What proportion of station entrances / exits without vending allow
    entrance?

``` r
subway_data %>% 
  filter(vending == "NO") %>%
  pull(entry) %>% 
  mean
```

    ## [1] 0.3770492

Answer: **37.7%** of station entrances are not vending allowed.

*I have reformatted the data so that route number and route name are
distinct variables.*

4.  How many distinct stations serve the A train?

``` r
subway_data %>% 
  pivot_longer(
    cols = starts_with("route"),
    names_to = "route_number",
    values_to = "route",
    values_transform = list(route = as.character)) %>% 
  filter(route == "A") %>% 
  select(station_name, line, route) %>% 
  distinct()
```

    ## # A tibble: 60 × 3
    ##    station_name                  line            route
    ##    <chr>                         <chr>           <chr>
    ##  1 Times Square                  42nd St Shuttle A    
    ##  2 125th St                      8 Avenue        A    
    ##  3 145th St                      8 Avenue        A    
    ##  4 14th St                       8 Avenue        A    
    ##  5 168th St - Washington Heights 8 Avenue        A    
    ##  6 175th St                      8 Avenue        A    
    ##  7 181st St                      8 Avenue        A    
    ##  8 190th St                      8 Avenue        A    
    ##  9 34th St                       8 Avenue        A    
    ## 10 42nd St                       8 Avenue        A    
    ## # … with 50 more rows

Answer: **60** distinct stations serve the A train.

Q5: Of the stations that serve the A train, how many are ADA compliant?

``` r
subway_data %>%
  pivot_longer(
    cols = starts_with("route"),
    names_to = "route_number",
    values_to = "route",
    values_transform = list(route = as.character)) %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line, route, ada) %>% 
  distinct()
```

    ## # A tibble: 17 × 4
    ##    station_name                  line             route ada  
    ##    <chr>                         <chr>            <chr> <lgl>
    ##  1 14th St                       8 Avenue         A     TRUE 
    ##  2 168th St - Washington Heights 8 Avenue         A     TRUE 
    ##  3 175th St                      8 Avenue         A     TRUE 
    ##  4 34th St                       8 Avenue         A     TRUE 
    ##  5 42nd St                       8 Avenue         A     TRUE 
    ##  6 59th St                       8 Avenue         A     TRUE 
    ##  7 Inwood - 207th St             8 Avenue         A     TRUE 
    ##  8 West 4th St                   8 Avenue         A     TRUE 
    ##  9 World Trade Center            8 Avenue         A     TRUE 
    ## 10 Times Square-42nd St          Broadway         A     TRUE 
    ## 11 59th St-Columbus Circle       Broadway-7th Ave A     TRUE 
    ## 12 Times Square                  Broadway-7th Ave A     TRUE 
    ## 13 8th Av                        Canarsie         A     TRUE 
    ## 14 Franklin Av                   Franklin         A     TRUE 
    ## 15 Euclid Av                     Fulton           A     TRUE 
    ## 16 Franklin Av                   Fulton           A     TRUE 
    ## 17 Howard Beach                  Rockaway         A     TRUE

Answer: Of the stations that serve the A train, **17** are ADA
compliant.

# Problem 2

Read, clean, and organize Mr. Trash Wheel dataset:

``` r
mr_trash_wheel = 
  read_excel(
    "Data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx",
    sheet = "Mr. Trash Wheel",
    range = "A2:N534",
    na = "") %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls),
    trash_wheel = "Mr.",
    dumpster = as.numeric(dumpster))
```

In the original excel datasheet for `Mr. Trash Wheel`, column 15, 16,
and 17 are either notes or empty cells. In addition to that, there are
some rows that do not have information related to a specific dumpster.
Those rows have empty cells, and I marked those empty cells with ‘NA’.
Then, I only selected columns that have “values”, and removed any rows
that has a missing value `NA`. Next, I rounded up the number of sports
balls to the nearest integer and converted the variable from numeric to
integer. I have also created a new variable `trash_wheel` and give it a
“value” `Mr.`, so that I can differentiate which data belongs to which
trash wheel when I combine `Mr. Trash Wheel` with
`Professor Trash Wheel`. Lastly, I have changed the variable type of
`dumpster` in `Mr. Trash Wheel` dataset from character to numeric, so
that it is synchronous to `Professor Trash Wheel` dataset, and that way
I can combine them to a single, tidy dataset.

Read, clean, and organize Professor Trash Wheel dataset:

``` r
prof_trash_wheel = 
  read_excel(
    "Data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx", 
    sheet = "Professor Trash Wheel", 
    range = "A2:N116",
    na = "") %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls),
    trash_wheel = "Professor")
```

Similar to the original `Mr. Trash Wheel` excel sheet, the original
excel datasheet for `Professor Trash Wheel` contains some rows that do
not have information related to a specific dumpster. Those rows have
empty cells, and I marked those empty cells with ‘NA’. I did not need to
select columns because there are no unnecessary columns. Then, I removed
the rows that have missing value `NA`. Again, I rounded up the number of
sports balls to the nearest integer and converted the variable from
numeric to integer. I have also created a new variable `trash_wheel` and
give it a “value” `Professor`, so that I can differentiate which data
belongs to which trash wheel when I combine `Mr. Trash Wheel` with
`Professor Trash Wheel`.

Finally, I double checked the variables and their types in both datasets
to make sure they are the same, so that I can combine them into a
single, neat and tidy dataset.

``` r
str(mr_trash_wheel)
```

    ## tibble [453 × 15] (S3: tbl_df/tbl/data.frame)
    ##  $ dumpster          : num [1:453] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ month             : chr [1:453] "May" "May" "May" "May" ...
    ##  $ year              : num [1:453] 2014 2014 2014 2014 2014 ...
    ##  $ date              : POSIXct[1:453], format: "2014-05-16" "2014-05-16" ...
    ##  $ weight_tons       : num [1:453] 4.31 2.74 3.45 3.1 4.06 2.71 1.91 3.7 2.52 3.76 ...
    ##  $ volume_cubic_yards: num [1:453] 18 13 15 15 18 13 8 16 14 18 ...
    ##  $ plastic_bottles   : num [1:453] 1450 1120 2450 2380 980 1430 910 3580 2400 1340 ...
    ##  $ polystyrene       : num [1:453] 1820 1030 3100 2730 870 2140 1090 4310 2790 1730 ...
    ##  $ cigarette_butts   : num [1:453] 126000 91000 105000 100000 120000 90000 56000 112000 98000 130000 ...
    ##  $ glass_bottles     : num [1:453] 72 42 50 52 72 46 32 58 49 75 ...
    ##  $ grocery_bags      : num [1:453] 584 496 1080 896 368 ...
    ##  $ chip_bags         : num [1:453] 1162 874 2032 1971 753 ...
    ##  $ sports_balls      : int [1:453] 7 5 6 6 7 5 3 6 6 7 ...
    ##  $ homes_powered     : num [1:453] 0 0 0 0 0 0 0 0 0 0 ...
    ##  $ trash_wheel       : chr [1:453] "Mr." "Mr." "Mr." "Mr." ...

``` r
str(prof_trash_wheel)
```

    ## tibble [71 × 15] (S3: tbl_df/tbl/data.frame)
    ##  $ dumpster          : num [1:71] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ month             : chr [1:71] "January" "January" "February" "February" ...
    ##  $ year              : num [1:71] 2017 2017 2017 2017 2017 ...
    ##  $ date              : POSIXct[1:71], format: "2017-01-02" "2017-01-30" ...
    ##  $ weight_tons       : num [1:71] 1.79 1.58 2.32 3.72 1.45 1.71 1.82 2.37 2.64 2.78 ...
    ##  $ volume_cubic_yards: num [1:71] 15 15 18 15 15 15 15 15 15 15 ...
    ##  $ plastic_bottles   : num [1:71] 1950 9540 8350 8590 7830 8210 9830 9240 9540 8230 ...
    ##  $ polystyrene       : num [1:71] 6080 11230 9210 1030 9950 ...
    ##  $ cigarette_butts   : num [1:71] 19700 17600 12000 13000 16000 14000 17000 15000 17000 13000 ...
    ##  $ glass_bottles     : num [1:71] 8 14 19 21 18 23 26 14 28 22 ...
    ##  $ grocery_bags      : num [1:71] 3100 5630 6430 5870 7450 ...
    ##  $ chip_bags         : num [1:71] 15600 16700 12400 11030 15340 ...
    ##  $ sports_balls      : int [1:71] 7 0 0 0 0 0 0 0 0 0 ...
    ##  $ homes_powered     : num [1:71] 29.8 26.3 38.7 62 24.2 ...
    ##  $ trash_wheel       : chr [1:71] "Professor" "Professor" "Professor" "Professor" ...

Combine Mr. Trash Wheel and Professor Trash Wheel into one dataset:

``` r
trash_wheels = 
  bind_rows(mr_trash_wheel, prof_trash_wheel) %>% 
  janitor::clean_names()
```

Now that the two datasets have been merged, the new dataset
`trash_wheels` have 15 variables and 524 observations. Because both
datasets have exactly the same variable names and types, I am able to
combine them without having the variables being duplicated, and I can
still differentiate which data (or rows) refer to which trash wheel.

#### Questions

I will be using the merged dataset `trash_wheels` to answer the
following questions:

1.  what was the total weight of trash collected by Professor Trash
    Wheel?

``` r
total_trash_wt = 
  trash_wheels %>% 
  filter(trash_wheel == "Professor") %>% 
  pull(weight_tons) %>% 
  sum()
```

Answer: Professor Trash Wheel has collected a total of 135.5 tons of
trash.

2.  What was the total number of sports balls collected by Mr. Trash
    Wheel in 2020?

``` r
total_balls =
  trash_wheels %>% 
  filter(year == "2020", trash_wheel == "Mr.") %>% 
  pull(sports_balls) %>% 
  sum
```

Answer: Mr. Trash Wheel has collected 856 sports balls in 2020.

# Problem 3

Read, clean, and organize the `pols-month.csv` dataset:

``` r
pols = 
  read_csv("Data/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day")) %>% 
  mutate(
    year = as.integer(year),
    month = month.name[as.numeric(month)],
    day = as.integer(day),
    president = ifelse(prez_dem == 1, "democratic", "republican")) %>% 
  select(-prez_dem, - prez_gop, -day)
```

The original `pols-month.csv` dataset has 9 variables and 822
observations. The variable `mon` are dates written in this format:
`yyyy-mm-dd`. I created a new dataset named `pols` and separated the
dates in the variable `mon` into `year`, `month`, and `day`. Once
separated, the three new variables automatically become character
vectors. Hence, I changed `year` and `day` to integer vectors; and
changed `month` to numeric vector first, and then used the `mon.name`
function to change it to fully written month names (ie. January,
February, etc.).

Referring to the variables `prez_gop` and `prez_dem`, on any row, if
`prez_dem` = 1 (meaning the president at that time was democratic), then
`prez_gop` would never be 1, and it has to be 0. Therefore, I only used
`prez_dem` to create a new variable called `president`. If `prez_dem` =
1, then `president` = democratic; else if `prez_dem` = 0, then
`president` = republican.

Finally, I removed the variables `prez_dem`, `prez_gop`, and `day`. Now
the `pols` dataset has 9 variables and 822 observations.

Read, clean, and organize the `snp.csv` dataset:

``` r
snp = 
  read_csv("Data/snp.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    date = as.Date(date, format = "%m/%d/%y")) %>% 
  separate(date, into = c("year", "month", "day")) %>% 
  arrange(year, month, day) %>%
  select(-day) %>% 
  mutate(
    year = as.integer(year),
    month = month.name[as.numeric(month)])
```

The original `snp.csv` dataset has 2 variables and 787 observations. The
variable `date` are dates written in this format: `m/d/yy`. I created a
new dataset named `snp` and changed the date format to `yyyy-mm-dd`.
Then, I separated the dates into `year`, `month`, and `day`. Once
separated, the three new variables automatically become character
vectors. But then I realized the `month` were not in order, so I
arranged them in ascending order to be consistent with the `pols`
dataset. This will be helpful when we merge the datasets. Then, I
changed `year` and `day` to integer vectors; and changed `month` to
numeric vector first, and then used the `month.name` function to change
it to fully written month names (ie. January, February, etc.).

Finally, I removed the variable `day` because the same variable was
removed from the `pols` dataset as well. Now the `snp` dataset has 3
variables and 787 observations.

Read, clean, and organize the `unemployment.csv` dataset:

``` r
no_job = 
  read_csv("Data/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment_rate") %>% 
  mutate(
    month = recode
    (month, 
      jan = 1, feb = 2, mar = 3, apr = 4, may = 5, jun = 6, jul = 7, aug = 8, sep = 9, oct = 10, nov = 11, dec = 12),
    month = month.name[as.numeric(month)])
```

The original `unemployment.csv` dataset has 13 variables and 68
observations, and I created a new dataset named `no_job` from this csv
file. The first column was `year` and followed by “months”. Therefore, I
converted the “months” variables into one variable called `month`, and
whatever values that follows are grouped into a new variable named
`unemployment_rate` with respect to its corresponding month and year.
Then, I realized that the months under the `month` variable are written
in lowercase. I was not able to convert them directly to full word
months. Therefore, I recoded each of the lowercase, abbreviated month to
their corresponding month in numeric vector, and then changed them into
non-abbreviated months using the `month.name` function.

Now the `no_job` dataset has 3 variables and 816 observations and the
format, variable names and types are aligned with the `pols` and `snp`
datasets.

Join the datasets by merging `snp` into `pols`, and merge `no_job` into
the result:

``` r
pols_snp_unemp = 
 left_join(pols, snp, by = c("year", "month")) %>% 
 left_join(no_job, by = c("year", "month"))
```

Because the variables names and types, and the data is arranged in
ascending order, I am able to merge the datasets together by `year` and
`month` (because these two variables are common variables in all three
datasets).

Now the newly created dataset `pols_snp_unemp` contains 11 variables and
822 observations.

The 11 variables are:

-   2 common variables for all three datasets: `year` & `month`

-   7 variables from `pols`: `gov_gop`, `sen_gop`, `rep_gop`, `gov_dem`,
    `sen_dem`, `rep_dem` & `president`

-   1 variable from `snp`: `close`

-   1 variable from `no_job`: `unemployment_rate`

Because we merged the datasets based on the `pols` dataset, the `year`
spans from 1947 to 2015, but we only have data for `close` which began
in January, 1969, whearas the data for `unemployment_rate` only began in
January, 1948. Therefore, we have some missing values coded as `NA` in
those two columns.
